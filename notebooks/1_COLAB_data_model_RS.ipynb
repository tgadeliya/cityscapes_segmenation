{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0.5_COLAB_data_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NVygkdz95t3I",
        "outputId": "bf33b424-e7f9-4814-baf6-b4d3bb919f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os \n",
        "\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "\n",
        "import torch \n",
        "from torch import  optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms.functional import normalize as F_normalize\n",
        "\n",
        "!pip install tb-nightly\n",
        "!pip install future\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tb-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/64/e6221e5ecf7a64a7ee1218e7b3546d7c5975f505a0f495c9b85992bbdf4d/tb_nightly-1.14.0a20190509-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (0.15.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (1.16.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly) (3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->tb-nightly) (41.0.1)\n",
            "Installing collected packages: tb-nightly\n",
            "Successfully installed tb-nightly-1.14.0a20190509\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "taOAGWza5t3V"
      },
      "source": [
        "#### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SX2li2sT5t3X",
        "outputId": "7440d9de-0478-4876-b9bf-13201ecb8965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget --directory-prefix=data/  http://www.mimuw.edu.pl/~ciebie/cityscapes.tgz \n",
        "!tar -xzf data/cityscapes.tgz -C data/\n",
        "!python data/cityscapes/check_close.py # Check files\n",
        "!rm data/cityscapes.tgz\n",
        "!rm data/cityscapes/README.md\n",
        "!rm data/cityscapes/check_close.py\n",
        "!rm -r  data/cityscapes/.ipynb_checkpoints\n",
        "\n",
        "DATASET_FOLDER = \"data/cityscapes\"\n",
        "PIXELS_IN_PIC = 256 *256"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-09 11:21:12--  http://www.mimuw.edu.pl/~ciebie/cityscapes.tgz\n",
            "Resolving www.mimuw.edu.pl (www.mimuw.edu.pl)... 193.0.96.14\n",
            "Connecting to www.mimuw.edu.pl (www.mimuw.edu.pl)|193.0.96.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.mimuw.edu.pl/~ciebie/cityscapes.tgz [following]\n",
            "--2019-05-09 11:21:12--  https://www.mimuw.edu.pl/~ciebie/cityscapes.tgz\n",
            "Connecting to www.mimuw.edu.pl (www.mimuw.edu.pl)|193.0.96.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 310275605 (296M) [application/x-gzip]\n",
            "Saving to: ‘data/cityscapes.tgz’\n",
            "\n",
            "cityscapes.tgz      100%[===================>] 295.90M  10.9MB/s    in 26s     \n",
            "\n",
            "2019-05-09 11:21:39 (11.5 MB/s) - ‘data/cityscapes.tgz’ saved [310275605/310275605]\n",
            "\n",
            "rm: cannot remove 'data/cityscapes/.ipynb_checkpoints': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Hm2O_1wgOv",
        "colab_type": "text"
      },
      "source": [
        "#### Define device to train on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvsPwqOowgOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WD1cQiwK5t3e"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9INHkhP25t3g"
      },
      "source": [
        "#### Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "81j82LmC5t3i",
        "colab": {}
      },
      "source": [
        "class CityScapes(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, transform = None):\n",
        "        self.data_folder = path\n",
        "        self.len = len(os.listdir(path))\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        path_to_file = os.path.join(self.data_folder,os.listdir(self.data_folder)[idx-1])\n",
        "        image = io.imread(path_to_file)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2IXi6buX5t3o"
      },
      "source": [
        "#### Array with classes for segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-kvEN6LwgPA",
        "colab_type": "text"
      },
      "source": [
        "##### Function to convert RGB picture to feature map\n",
        "##### source: https://stackoverflow.com/questions/33196130/replacing-rgb-values-in-numpy-array-by-integer-is-extremely-slow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ZsLzk_wgPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RGB_to_idx(image, arr_to_idx):\n",
        "    image = image.dot(np.array([65536, 256, 1], dtype='int32'))\n",
        "    result = np.ndarray(shape=image.shape, dtype=int)\n",
        "    result[:,:] = -1\n",
        "    for rgb, idx in arr_to_idx.items():\n",
        "        rgb = rgb[0] * 65536 + rgb[1] * 256 + rgb[2]\n",
        "        result[image==rgb] = idx\n",
        "    return result\n",
        "\n",
        "def idx_to_RGB(image, idx_to_rgb):\n",
        "    result = np.ndarray(shape=(256,256,3), dtype=int)\n",
        "    result[:,:,:] = -1\n",
        "    for x in range(256):\n",
        "      for y in range(256):\n",
        "        result[x][y] = idx_to_arr[int(image[x][y])]\n",
        "    return result\n",
        "  \n",
        "  \n",
        "  \n",
        "check_array = np.array(\n",
        "    [[116, 17, 36],[152, 43,150],\n",
        "     [106,141, 34],[ 69, 69, 69],\n",
        "     [  2,  1,  3],[127, 63,126],\n",
        "     [222, 52,211],[  2,  1,140],\n",
        "     [ 93,117,119],\n",
        "     [180,228,182],[213,202, 43],\n",
        "     [ 79,  2, 80],[188,151,155],\n",
        "     [  9,  5, 91],[106, 75, 13],\n",
        "     [215, 20, 53],[110,134, 62],\n",
        "     [  8, 68, 98],[244,171,170],\n",
        "     [171, 43, 74],[104, 96,155],\n",
        "     [ 72,130,177],[242, 35,231],\n",
        "     [147,149,149],[ 35, 25, 34],\n",
        "     [155,247,151],[ 85, 68, 99],\n",
        "     [ 71, 81, 43],[195, 64,182],\n",
        "     [146,133, 92]]\n",
        ")\n",
        "\n",
        "arr_to_idx = {tuple(arr):idx for idx,arr in enumerate(check_array)}\n",
        "idx_to_arr = {idx: arr for idx,arr in enumerate(check_array)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MtU8bjRi5t30"
      },
      "source": [
        "#### Custom Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NCml-zfz5t32",
        "colab": {}
      },
      "source": [
        "class Split_N(object):\n",
        "    def __call__(self,sample):\n",
        "      return sample[:,:256,:].astype(\"float32\"), sample[:,256:,:].astype(\"float32\")\n",
        "\n",
        "class Split(object):\n",
        "    def __call__(self,sample):\n",
        "      return sample[:,:256,:], sample[:,256:,:]\n",
        "\n",
        "    \n",
        "# trsf = transforms.Compose([Split()])\n",
        "# dataset = CityScapes(DATASET_FOLDER, transform=trsf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SQPeh_YW5t4c"
      },
      "source": [
        "#### Create DataLoader for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ehXYlkY5t4e",
        "colab": {}
      },
      "source": [
        "# indices = np.arange(dataset.__len__())\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# # Random indices for training and validation Ratio 2975 / 500 \n",
        "# val_indices, train_indices =  indices[:500], indices[500:]\n",
        "\n",
        "# train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "# val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "# # train_loader = DataLoader(dataset, batch_size = 8, sampler = train_sampler) \n",
        "# # val_loader = DataLoader(dataset, batch_size = 8, sampler = val_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXwDWfAWloc_",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate *mean* and *std*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_ZjF_mYmp6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_loader = DataLoader(dataset, batch_size = len(train_sampler.indices), sampler = train_sampler) \n",
        "#for data,_ in train_loader:\n",
        "#     std = [data[:,:,:,0].std(),data[:,:,:,1].std(),data[:,:,:,2].std()]\n",
        "#     mean = [data[:,:,:,0].mean(),data[:,:,:,1].mean(),data[:,:,:,2].mean()]    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANiBj7JA7ADG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HorizontalFlip_Normalize(object):\n",
        "    \n",
        "    def __init__(self,mean,std):\n",
        "      self.mean = mean\n",
        "      self.std = std\n",
        "      \n",
        "    def __call__(self,sample):\n",
        "        X,y = sample\n",
        "        \n",
        "        y = RGB_to_idx(y,arr_to_idx)\n",
        "        if np.random.random() > 0.5:\n",
        "            X[:], y[:] = X[:,::-1,:],y[:,::-1]\n",
        "            \n",
        "        X = transforms.functional.to_tensor(X)\n",
        "        return (F_normalize(X, self.mean, self.std), torch.from_numpy(y))\n",
        "      \n",
        "class HorizontalFlip(object):\n",
        "   \n",
        "    def __call__(self,sample):\n",
        "        X,y = sample\n",
        "        \n",
        "        y = RGB_to_idx(y,arr_to_idx)\n",
        "        if np.random.random() > 0.5:\n",
        "            X[:], y[:] = X[:,::-1,:],y[:,::-1]\n",
        "            \n",
        "        X = transforms.functional.to_tensor(X)\n",
        "        return (X, torch.from_numpy(y))\n",
        "      \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whL_iF7N9LJJ",
        "colab_type": "text"
      },
      "source": [
        "#### Data Loader with normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJn6VRz9KjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_calc = [22.0289,22.0289,22.0289]\n",
        "std_calc = [47.1833,47.7054,47.2338]\n",
        "\n",
        "trsf = transforms.Compose([Split(),HorizontalFlip()])\n",
        "dataset = CityScapes(DATASET_FOLDER, transform=trsf)\n",
        "\n",
        "\n",
        "\n",
        "indices = np.arange(dataset.__len__())\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Random indices for training and validation Ratio 2975 / 500 \n",
        "val_indices, train_indices =  indices[:500], indices[500:]\n",
        "\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size = 8, sampler = train_sampler) \n",
        "val_loader = DataLoader(dataset, batch_size = 8, sampler = val_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JLGBTv7S7uD",
        "colab_type": "code",
        "outputId": "3c83cf43-9b7f-488c-e3f8-29bf46948b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "for i in range(2):\n",
        "  plt.imshow(idx_to_RGB(dataset[1024+i][1],idx_to_arr))\n",
        "  plt.pause(1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j9TLYtqTusWmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXcwOzIe8N3u",
        "colab_type": "text"
      },
      "source": [
        "#### Class balance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_d5vDW68JqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_histogram(dataset):\n",
        "  dict_classes  = { idx:0 for idx in range(30)}\n",
        "  \n",
        "  for i in range(dataset.len):\n",
        "      _, y = dataset[i]\n",
        "      for class_idx in dict_classes.keys():\n",
        "        dict_classes[class_idx] += np.sum(np.where(y == class_idx, 1, 0))\n",
        "  return dict_classes \n",
        "classes_freq_dictionary = make_histogram(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLBUswJkWPzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_weight(dict_hist):\n",
        "    num_class = len(dict_hist.keys())\n",
        "    weight = np.empty(num_class)\n",
        "    \n",
        "    total_pixels = np.sum( list(dict_hist.values()) )\n",
        "    \n",
        "    for i in range(num_class):\n",
        "      weight[i] =  dict_hist[i] /total_pixels\n",
        "    return torch.Tensor(weight)\n",
        "global weight  \n",
        "weight = make_weight(classes_freq_dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvql4nUw8gf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.bar(classes_freq_dictionary.keys(), classes_freq_dictionary.values(), width=2,);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YkiHZp_A5t4l"
      },
      "source": [
        "### Defining U-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YKWVOBaf5t4n",
        "colab": {}
      },
      "source": [
        "def make_block(in_channels, out_channels):\n",
        "    block = nn.Sequential(nn.ReplicationPad2d(1),\n",
        "                              nn.Conv2d(in_channels, out_channels, 3, bias = False),\n",
        "                              nn.ReLU(),\n",
        "                              nn.BatchNorm2d(out_channels),\n",
        "                              nn.ReplicationPad2d(1),\n",
        "                              nn.Conv2d(out_channels, out_channels, 3, bias = False),\n",
        "                              nn.ReLU(),\n",
        "                              nn.BatchNorm2d(out_channels)\n",
        "                             )\n",
        "    if (device.type == \"cuda\"):\n",
        "        block.type(torch.cuda.FloatTensor)\n",
        "    return block"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YHS95_hn5t4s",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, basic_chl,num_classes = 30,image_channels = 3):\n",
        "        super(UNet, self).__init__()\n",
        "        \n",
        "        #Calculate channels based on basic channel\n",
        "        BL1_chl, BL2_chl, BL3_chl, BL4_chl, BL5_chl= [basic_chl * i for i in [1,2,4,8,16]]\n",
        "        \n",
        "        #Encoder blocks\n",
        "        self.ENC_BL1 = make_block(image_channels,BL1_chl)\n",
        "        self.ENC_BL2 = make_block(BL1_chl,BL2_chl)\n",
        "        self.ENC_BL3 = make_block(BL2_chl,BL3_chl)\n",
        "        self.ENC_BL4 = make_block(BL3_chl,BL4_chl)\n",
        "        self.ENC_BL5 = make_block(BL4_chl,BL5_chl)\n",
        "        \n",
        "        #MaxPool for downsampling\n",
        "        self.MaxPool = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        #UpConv for upsampling\n",
        "        self.UpConv1 = nn.ConvTranspose2d(BL5_chl, BL4_chl, 2, stride = 2)\n",
        "        self.UpConv2 = nn.ConvTranspose2d(BL4_chl, BL3_chl, 2, stride = 2)\n",
        "        self.UpConv3 = nn.ConvTranspose2d(BL3_chl, BL2_chl, 2, stride = 2)\n",
        "        self.UpConv4 = nn.ConvTranspose2d(BL2_chl, BL1_chl, 2, stride = 2)\n",
        "        \n",
        "        #Decoder blocks\n",
        "        self.DEC_BL1 = make_block(BL5_chl,BL4_chl)\n",
        "        self.DEC_BL2 = make_block(BL4_chl,BL3_chl)\n",
        "        self.DEC_BL3 = make_block(BL3_chl,BL2_chl)\n",
        "        self.DEC_BL4 = make_block(BL2_chl,BL1_chl)\n",
        "        \n",
        "        # Last convolution\n",
        "        self.Final_CONV = nn.Conv2d(basic_chl, num_classes, 1)\n",
        "        \n",
        "    \n",
        "    def forward(self,X):\n",
        "        # Encoder\n",
        "        ENC_1_out = self.ENC_BL1.forward(X)\n",
        "        MaxENC_1_out = self.MaxPool.forward(ENC_1_out)\n",
        "        \n",
        "        ENC_2_out = self.ENC_BL2.forward(MaxENC_1_out)\n",
        "        MaxENC_2_out = self.MaxPool.forward(ENC_2_out)\n",
        "        \n",
        "        ENC_3_out = self.ENC_BL3.forward(MaxENC_2_out)\n",
        "        MaxENC_3_out = self.MaxPool.forward(ENC_3_out)\n",
        "        \n",
        "        ENC_4_out = self.ENC_BL4.forward(MaxENC_3_out)\n",
        "        MaxENC_4_out = self.MaxPool.forward(ENC_4_out)\n",
        "                \n",
        "        # Bridge to Decoder\n",
        "        ENC_5_out = self.ENC_BL5.forward(MaxENC_4_out)\n",
        "        UpENC_5_out = self.UpConv1.forward(ENC_5_out)  \n",
        "        \n",
        "        #Decoder\n",
        "        DEC_1_in = torch.cat((UpENC_5_out,ENC_4_out), dim = 1)\n",
        "        DEC_1_out = self.DEC_BL1.forward( DEC_1_in)\n",
        "        UpDEC_1_out = self.UpConv2.forward(DEC_1_out)\n",
        "        \n",
        "        \n",
        "        DEC_2_in = torch.cat((UpDEC_1_out,ENC_3_out), dim = 1)\n",
        "        DEC_2_out = self.DEC_BL2.forward(DEC_2_in)\n",
        "        UpDEC_2_out = self.UpConv3.forward(DEC_2_out)\n",
        "        \n",
        "        DEC_3_in = torch.cat((UpDEC_2_out,ENC_2_out), dim = 1)\n",
        "        DEC_3_out = self.DEC_BL3.forward(DEC_3_in)\n",
        "        UpDEC_3_out = self.UpConv4.forward(DEC_3_out)\n",
        "        \n",
        "        DEC_4_in = torch.cat((UpDEC_3_out,ENC_1_out), dim = 1)\n",
        "        DEC_4_out = self.DEC_BL4.forward(DEC_4_in)\n",
        "          \n",
        "        #Final Convolution    \n",
        "        segmenatation_map = self.Final_CONV.forward(DEC_4_out)\n",
        "    \n",
        "        return segmenatation_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieUdserVqmCb",
        "colab_type": "text"
      },
      "source": [
        "### Compute Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JuNedfah5t45",
        "colab": {}
      },
      "source": [
        "def compute_validation_accuracy(model, val_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    acc_accum = 0.0\n",
        "    PIXELS_IN_BATCH = PIXELS_IN_PIC * val_loader.batch_size\n",
        "    for idx,(X,y) in enumerate(val_loader):\n",
        "            \n",
        "        x = X.to(device)\n",
        "        y = y.to(device)\n",
        "                \n",
        "        prediction = torch.argmax( model(x), dim = 1)   \n",
        "        acc_accum += float(torch.sum(prediction == y))/PIXELS_IN_BATCH\n",
        "        \n",
        "    accuracy = acc_accum / val_loader.__len__()    \n",
        "    return accuracy\n",
        "  \n",
        "\n",
        "def visualize_random_sample(model, loader = val_loader,num_samples = 3):\n",
        "    model.eval()\n",
        "    random_idx = np.random.choice(loader.sampler.indices, size = num_samples)\n",
        "    fig, axs = plt.subplots(num_samples,3, figsize=(10,10))\n",
        "    \n",
        "    for ax in axs:\n",
        "      for obj in ax:\n",
        "          obj.axis(\"off\")\n",
        "    \n",
        "    for i,idx in enumerate(random_idx):\n",
        "        X,y = dataset[idx]\n",
        "        \n",
        "        \n",
        "        axs[i,0].imshow(X.permute(1,2,0))\n",
        "        axs[i,1].imshow(idx_to_RGB(y, idx_to_arr))\n",
        "                \n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        pred = torch.argmax( model(X.unsqueeze(0)) ,dim=1) \n",
        "        axs[i,2].imshow(idx_to_RGB(pred[0].cpu(), idx_to_arr))\n",
        "        \n",
        "        \n",
        "        idx_acc = float(torch.sum(pred == y))/PIXELS_IN_PIC\n",
        "        print(\"accuracy on {0} validation example : {1:.2f} \".format(i,idx_acc)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TOjIT6f75t5N"
      },
      "source": [
        "### Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UsTEd0nI5t5O",
        "colab": {}
      },
      "source": [
        "def train_model(model, optimizer, loss_function, scheduler_obj ,train_loader, val_loader = None, verbose = False, num_epochs=5):         \n",
        "    train_loss_history, train_acc_history, val_acc_history = [], [], []\n",
        "    \n",
        "    scheduler = scheduler_obj\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "    \n",
        "        train_acc_accum = 0.0\n",
        "        running_loss = 0\n",
        "        \n",
        "        for x,y in train_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            output = model(x) # batch_size x num_classes x height x width\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss = loss_function(output,y)\n",
        "            train_acc_accum += float(torch.sum(pred == y))/ (x.shape[0] * PIXELS_IN_PIC) ##ACC_METRIC\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "        train_acc = train_acc_accum / train_loader.__len__()\n",
        "        val_acc = \"-\" if (val_loader == None) else compute_validation_accuracy(model, val_loader)\n",
        "        loss_norm = running_loss / train_loader.__len__()\n",
        "        scheduler.step(loss_norm)\n",
        "        \n",
        "        if (verbose):\n",
        "          print(\"Epoch: {0}, tr_loss = {1:.4f} , tr_acc = {2:.3f}, val_acc = {3}\".format(epoch+1, loss_norm, train_acc, val_acc) )\n",
        "        \n",
        "        train_loss_history.append(loss_norm)\n",
        "        train_acc_history.append(train_acc)\n",
        "        val_acc_history.append(val_acc)\n",
        "        \n",
        "    return train_loss_history, train_acc_history, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yVRU9m5h5t5V"
      },
      "source": [
        "### Toy Dataset for sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJWZstuW5t5X",
        "colab": {}
      },
      "source": [
        "### Create toy dataset to check  implementation\n",
        "np.random.seed(42)\n",
        "\n",
        "tr_toy_size = 5\n",
        "val_toy_size = 1 \n",
        "toy_batch = 5\n",
        "\n",
        "tr_toy_ind = np.random.choice(train_indices, size = tr_toy_size) \n",
        "val_toy_ind =np.random.choice(val_indices, size = val_toy_size) \n",
        "\n",
        "\n",
        "train_toy_sampler = torch.utils.data.SubsetRandomSampler(tr_toy_ind)\n",
        "val_toy_sampler = torch.utils.data.SubsetRandomSampler(val_toy_ind) \n",
        "\n",
        "train_toy_loader = DataLoader(dataset=dataset, batch_size=toy_batch, sampler= train_toy_sampler)\n",
        "val_toy_loader = DataLoader(dataset=dataset, batch_size= toy_batch, sampler = val_toy_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZflP1eWBKwH",
        "colab_type": "text"
      },
      "source": [
        "### Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaJq8XFmBC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = UNet(128)\n",
        "model.to(device)\n",
        "loss = torch.nn.CrossEntropyLoss(weight=weight)\n",
        "\n",
        "if (device.type == \"cuda\"):\n",
        "    model.type(torch.cuda.FloatTensor)\n",
        "    loss.type(torch.cuda.FloatTensor)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr = 1e-3,weight_decay = 1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode = \"min\",patience = 1, verbose =True, threshold=0.01)\n",
        "\n",
        "torch.optim.lr_scheduler.CosineAnnealingLR()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a34e3H6Z0wn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_acc_history,\"C1\")\n",
        "plt.plot(val_acc_history, 'b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QKGFbbBQP-",
        "colab_type": "text"
      },
      "source": [
        "### Training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG8t1QPZG1_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        " \n",
        "\n",
        "writer = SummaryWriter(\"runs/exp1\",)\n",
        "\n",
        "\n",
        "# grid = torchvision.utils.make_grid(images)\n",
        "# writer.add_image('images', grid, 0)\n",
        "writer.add_graph(model, next(iter(train_loader))[0].to(device) )\n",
        "writer.add_text(\"params\", \"lr=10\")\n",
        "writer.add_scalar(\"lr\",optim.param_groups[0][\"lr\"])\n",
        "writer.close()\n",
        "\n",
        "from tensorflow import summary\n",
        "%load_ext tensorboard\n",
        "\n",
        "torch.tf\n",
        "\n",
        "\n",
        "writer.add_graph(model, next(iter(train_loader))[0].to(device) )\n",
        "writer. add_text(\"params\", \"lr=10\")\n",
        "writer.file_writer.add_scalar(\"lr\",optim.param_groups[0][\"lr\"])\n",
        "\n",
        "%tensorboard --logdir=content/runs/exp1/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DhLpst_W5t5p"
      },
      "source": [
        "### Random Hyper-parameter search\n",
        "    Parameters:\n",
        "    - learning rate\n",
        "    - weight decay\n",
        "    - optimizers\n",
        "    - lr schedule\n",
        "    - loss function\n",
        "    \n",
        "    Algorithm:\n",
        "    1) Get random sample from search space\n",
        "    2) Define model with given parameters and train 1 epoch. Check whether training starts well\n",
        "    3) \n",
        "    5) Final search performs N times and return best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x5ZWDZ2b5t5r",
        "colab": {}
      },
      "source": [
        "dict_params = {\n",
        "    \"lr\" : [-10,-3],\n",
        "    \"L2\" : [-6,-1],\n",
        "    \"lr_anneal_factor\" : [0.01, 0.5, 0.9],\n",
        "    \"lr_anneal_size\" : [1,3,10],\n",
        "    #\"scheduler\" : [ [ \"Cyclic\" , [3,4,5,10], [0.1,0.5,0.93] ], [ [\"Cosine\",[1],[2]]] ],\n",
        "    \"loss\" : [\"CCE\"],\n",
        "    \"optimizer\": [\"Adam\", \"SGD\"]\n",
        "}\n",
        "\n",
        "def make_sample(params):\n",
        "    sample_dict={}\n",
        "  \n",
        "    for key,value in params.items():\n",
        "        if  (key == \"optimizer\"):\n",
        "            sampled_param = np.random.choice(value)  \n",
        "        elif (key == \"loss\"):\n",
        "            sampled_param = torch.nn.CrossEntropyLoss\n",
        "    #     elif (key == \"scheduler\"):\n",
        "    #       sch  = np.random.choice(value)\n",
        "    #       sampl_param = [np.random.choice(x) for x in sch[1:]]\n",
        "    #       sampled_param = [sch[0],sampl_param]\n",
        "        elif (key == \"lr_aneal_factor\" or key == \"lr_aneal_factor\") :\n",
        "            sampled_param = np.random.choice(value)\n",
        "        else:\n",
        "            sampled_param = 10 ** np.random.uniform(low = value[0], high = value[1]) \n",
        "        sample_dict[key] = sampled_param\n",
        "        \n",
        "    return sample_dict\n",
        "\n",
        "def Random_search(chan_fact, dict_of_params, N, train_loader, val_loader):\n",
        "    dict_evaluations = {}\n",
        "    \n",
        "    for i in range(N):\n",
        "        \n",
        "        # Get random parameters\n",
        "        sample = make_sample(dict_of_params)\n",
        "    \n",
        "        # Define model\n",
        "        model_def = UNet(chan_fact)\n",
        "        loss = sample[\"loss\"](weight)\n",
        "        \n",
        "        if (device.type == \"cuda\"):\n",
        "            model_def.type(torch.cuda.FloatTensor)\n",
        "            loss.type(torch.cuda.FloatTensor)\n",
        "        \n",
        "        if (sample[\"optimizer\"] == \"Adam\"):\n",
        "            optimizer = torch.optim.Adam(model_def.parameters(), lr = sample[\"lr\"], weight_decay = sample[\"L2\"])\n",
        "        elif (sample[\"optimizer\"] == \"SGD\"):\n",
        "            optimizer = torch.optim.SGD(model_def.parameters(), lr = sample[\"lr\"], momentum = 0.9 , weight_decay = sample[\"L2\"] )         \n",
        "        \n",
        "#         if (sample[\"scheduler\"][0] == \"Cyclic\"):\n",
        "#             scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, *sample[\"scheduler\"][1])\n",
        "#         elif (sample[\"scheduler\"][0] == \"Cosine\"):\n",
        "#             scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, *sample[\"scheduler\"][1])\n",
        "#         elif (sample[\"scheduler\"][0] == \"ReduceLRonPlateau\"):\n",
        "#             scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau (optimizer, *sample[\"scheduler\"][1])\n",
        "        \n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size = sample[\"lr_anneal_size\"], gamma = sample[\"lr_anneal_factor\"] )\n",
        "                       \n",
        "        #perform training\n",
        "        train_loss_h, train_acc, val_acc_history = train_model(model_def, optimizer, loss, scheduler, train_loader, val_loader = val_loader,verbose = False, num_epochs = 20)\n",
        "        \n",
        "        \n",
        "        #dict_evaluations.append([sample, [train_loss_h, train_acc, val_acc_history]])\n",
        "                  \n",
        "        print(\"Sampled {0}\".format(i))    \n",
        "        dict_evaluations[tuple([(name,val) for name,val in sample.items()])] = [train_loss_h, train_acc, val_acc_history]\n",
        "        \n",
        "    return dict_evaluations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xtipf62xVEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_model = Random_search(64, dict_params, 20, train_toy_loader, val_toy_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CFf0CLkL1au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for params, (tr_loss, tr_acc,val_acc) in dict_model.items():\n",
        "    print(params)\n",
        "    plt.plot(tr_acc, \"b\")\n",
        "    plt.plot(val_acc, \"C1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7a-wd7qcvqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter(\"runs/new2\")\n",
        "\n",
        "model = UNet(64)\n",
        "model.to(device)\n",
        "\n",
        "images = next(iter(train_toy_loader))[0].to(device)\n",
        "\n",
        "\n",
        "writer.add_graph(model, images)\n",
        "writer.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ7SUKiWdAWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir=runs/new2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}